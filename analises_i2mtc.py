# -*- coding: utf-8 -*-
"""analises_i2mtc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uf8rZHLnedNUKFnBYzXV4qO7hn6gOOTd
"""

!pip install scikit-posthocs

import pandas as pd
import os

import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
from google.colab import drive
import matplotlib.pyplot as plt
from lightgbm import LGBMRegressor
from sklearn.utils import resample
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

'''
# Montar o Google Drive para acessar os arquivos
drive.mount('/content/drive')

# Carregar dados do arquivo CSV
#file_path = '/content/drive/MyDrive/Mestrado/metrics_results/metrics_results_w7784.csv'  # Substitua pelo caminho do seu arquivo
#dt = pd.read_csv(file_path)  # Certifique-se de que o índice seja carregado como uma coluna
'''

'''
# Caminho para o arquivo CSV
file_path = '/content/drive/MyDrive/Mestrado/metrics_results03/metrics_results_03_w7784.csv'
dt = pd.read_csv(file_path)

# Nome do método que deseja extrair (exemplo: 'Full Conformal')
method_name = 'Full Conformal'  # Substitua pelo método desejado

# Selecionar diretamente as linhas pelas posições para RMSE (3), R² (4) e MAE (5)
# Como as métricas estão em ordem e sabemos que RMSE está na linha 3, R² na 4, e MAE na 5
metrics_df = pd.DataFrame({
    'RMSE': eval(dt[method_name].iloc[3]),  # Linha 3 para RMSE
    'R2': eval(dt[method_name].iloc[4]),    # Linha 4 para R²
    'MAE': eval(dt[method_name].iloc[5])    # Linha 5 para MAE
})

# Visualizar as primeiras linhas para verificar o resultado
print(metrics_df.head())

# Opcional: Salvar o DataFrame resultante em um novo arquivo CSV
output_path = '/content/drive/MyDrive/Mestrado/metrics_results03/model_results_03_w7784.csv'
metrics_df.to_csv(output_path, index=False)

import matplotlib.pyplot as plt

# Gerar box-plots para as métricas extraídas
plt.figure(figsize=(12, 6))

# Criar um subplot para cada métrica
plt.subplot(1, 3, 1)
plt.boxplot(metrics_df['RMSE'])
plt.title('Box-Plot de RMSE')
plt.ylabel('Valor')

plt.subplot(1, 3, 2)
plt.boxplot(metrics_df['R2'])
plt.title('Box-Plot de R²')
plt.ylabel('Valor')

plt.subplot(1, 3, 3)
plt.boxplot(metrics_df['MAE'])
plt.title('Box-Plot de MAE')
plt.ylabel('Valor')

# Ajustar layout
plt.tight_layout()
plt.show()
'''

"""BOX-PLOTS RMSE POR JANELA"""

### upload arquivo
from google.colab import files
uploaded = files.upload()

# Colunas de interesse para o boxplot
colunas_de_interesse = ['SW100', 'SW150', 'SW190', 'SW250', 'SW360', 'SW720']  # Ajuste se necessário

# Verificar se as colunas existem no DataFrame
for col in colunas_de_interesse:
    if col not in df.columns:
        raise ValueError(f"A coluna {col} não foi encontrada no arquivo Excel.")

from google.colab import files
import matplotlib.pyplot as plt
import seaborn as sns

# Paleta de cores pastel do Seaborn
palette = sns.color_palette("pastel", len(colunas_de_interesse))  # Uma cor para cada coluna

# Configurar o estilo do gráfico
plt.rcParams.update({
    "font.family": "serif",
    "axes.edgecolor": "black",
    "axes.linewidth": 1.2,
    "axes.grid": True,
    "grid.color": "gray",
    "grid.alpha": 0.5,
    "grid.linestyle": "--",
    "grid.linewidth": 0.5,
    "font.size": 12,
    "text.usetex": False  # Desativar o uso de LaTeX
})

# Gerar o boxplot
fig, ax = plt.subplots(figsize=(7.16, 4))
box = df[colunas_de_interesse].boxplot(ax=ax, patch_artist=True, return_type='dict')

# Aplicar a paleta pastel às caixas
for patch, color in zip(box['boxes'], palette):
    patch.set_facecolor(color)

# Personalizar as propriedades restantes
for whisker in box['whiskers']:
    whisker.set(color="black", linewidth=1.2)
for cap in box['caps']:
    cap.set(color="black", linewidth=1.2)
for median in box['medians']:
    median.set(color="orange", linewidth=1.5)

# Adicionar título e rótulos
ax.set_xlabel('Window Size', fontsize=16)
ax.set_ylabel('RMSE (t/h)', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=10, width=1)

# Salvar o gráfico como PDF antes de exibir
plt.savefig('boxplot_window_size.pdf', format='pdf', bbox_inches='tight')

# Exibir o gráfico
plt.show()

# Fazer o download do arquivo PDF
files.download('boxplot_window_size.pdf')

"""BOX-PLOTS MAE POR JANELA"""

### upload arquivo
from google.colab import files
uploaded = files.upload()

df = pd.read_excel('MAE_RESULTS.xlsx')
df

# Colunas de interesse para o boxplot
colunas_de_interesse = ['SW100', 'SW150', 'SW190', 'SW250', 'SW360', 'SW720']  # Ajuste se necessário

# Verificar se as colunas existem no DataFrame
for col in colunas_de_interesse:
    if col not in df.columns:
        raise ValueError(f"A coluna {col} não foi encontrada no arquivo Excel.")

from google.colab import files
import matplotlib.pyplot as plt
import seaborn as sns

# Paleta de cores pastel do Seaborn
palette = sns.color_palette("pastel", len(colunas_de_interesse))  # Uma cor para cada coluna

# Configurar o estilo do gráfico
plt.rcParams.update({
    "font.family": "serif",
    "axes.edgecolor": "black",
    "axes.linewidth": 1.2,
    "axes.grid": True,
    "grid.color": "gray",
    "grid.alpha": 0.5,
    "grid.linestyle": "--",
    "grid.linewidth": 0.5,
    "font.size": 12,
    "text.usetex": False  # Desativar o uso de LaTeX
})

# Gerar o boxplot
fig, ax = plt.subplots(figsize=(7.16, 4))
box = df[colunas_de_interesse].boxplot(ax=ax, patch_artist=True, return_type='dict')

# Aplicar a paleta pastel às caixas
for patch, color in zip(box['boxes'], palette):
    patch.set_facecolor(color)

# Personalizar as propriedades restantes
for whisker in box['whiskers']:
    whisker.set(color="black", linewidth=1.2)
for cap in box['caps']:
    cap.set(color="black", linewidth=1.2)
for median in box['medians']:
    median.set(color="orange", linewidth=1.5)

# Adicionar título e rótulos
ax.set_xlabel('Window Size', fontsize=16)
ax.set_ylabel('MAE (t/h)', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=10, width=1)

# Salvar o gráfico como PDF antes de exibir
plt.savefig('boxplot_window_size.pdf', format='pdf', bbox_inches='tight')

# Exibir o gráfico
plt.show()

# Fazer o download do arquivo PDF
files.download('boxplot_window_size.pdf')

"""
SHAPIRO-WILK TEST para verificar a normalidade Dados de Cobertura
"""

### upload arquivo
from google.colab import files
uploaded = files.upload()

import os

# Remover o arquivo antigo, se ainda existir
if os.path.exists("cobertura_results.xlsx"):
    os.remove("cobertura_results.xlsx")

from google.colab import files
uploaded = files.upload()  # Refaça o upload do arquivo atualizado

df = pd.read_excel('cobertura_results.xlsx')
df

from scipy.stats import shapiro

# Selecionar as colunas desejadas como uma lista
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']

# Iterar sobre cada coluna e aplicar o teste Shapiro-Wilk
for column in columns:
    data = df[column]  # Selecionar os dados da coluna
    stat, p_value = shapiro(data)
    print(f"Coluna: {column}")
    print(f"Estatística do teste: {stat}")
    print(f"P-valor: {p_value}")
    if p_value > 0.05:
        print("Não rejeitamos a hipótese nula: os dados seguem uma distribuição normal.\n")
    else:
        print("Rejeitamos a hipótese nula: os dados não seguem uma distribuição normal.\n")

"""O Teste de Kruskal-Wallis: pra determina se há diferenças significativas entre os grupos. E o Teste de Dunn: Pra identificar quais grupos específicos apresentam diferenças significativas.  O ajuste de Bonferroni é usado para evitar falsos positivos."""

import pandas as pd
from scipy.stats import kruskal
import scikit_posthocs as sp

# Supondo que você tenha carregado seus dados no DataFrame `df`
# Certifique-se de que as colunas correspondem aos grupos mencionados
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']
data = df[columns]

# Separar os valores de cada grupo
t_student = data['T-Student']
full = data['Full']
bootstrap = data['Bootstrap']
split = data['Split']

# Aplicar o teste de Kruskal-Wallis
stat, p_value = kruskal(t_student, full, bootstrap, split)
print(f"Estatística do teste: {stat}")
print(f"P-valor: {p_value}")

if p_value < 0.05:
    print("Rejeitamos a hipótese nula: pelo menos um dos grupos é diferente.")
else:
    print("Não rejeitamos a hipótese nula: todos os grupos têm distribuições semelhantes.")

# Organizar os dados no formato longo para o teste de Dunn
data_long = pd.melt(data.reset_index(), id_vars=['index'], value_vars=columns)
data_long.columns = ['Index', 'Group', 'Value']

# Verificar se as colunas foram configuradas corretamente
assert 'Value' in data_long.columns, "A coluna 'Value' não está no DataFrame."
assert 'Group' in data_long.columns, "A coluna 'Group' não está no DataFrame."

# Aplicar o teste de Dunn com ajuste Bonferroni
posthoc = sp.posthoc_dunn(data_long, val_col='Value', group_col='Group', p_adjust='bonferroni')

print("\nResultados do teste de Dunn (pós-hoc):")
print(posthoc)

"""SHAPIRO-WILK TEST para verificar a normalidade Dados de Largura"""

### upload arquivo
from google.colab import files
uploaded = files.upload()

df = pd.read_excel('largura_results.xlsx')
df

from scipy.stats import shapiro

# Selecionar as colunas desejadas como uma lista
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']

# Iterar sobre cada coluna e aplicar o teste Shapiro-Wilk
for column in columns:
    data = df[column]  # Selecionar os dados da coluna
    stat, p_value = shapiro(data)
    print(f"Coluna: {column}")
    print(f"Estatística do teste: {stat}")
    print(f"P-valor: {p_value}")
    if p_value > 0.05:
        print("Não rejeitamos a hipótese nula: os dados seguem uma distribuição normal.\n")
    else:
        print("Rejeitamos a hipótese nula: os dados não seguem uma distribuição normal.\n")

"""O Teste de Kruskal-Wallis: pra determina se há diferenças significativas entre os grupos. E o Teste de Dunn: Pra identificar quais grupos específicos apresentam diferenças significativas.  O ajuste de Bonferroni é usado para evitar falsos positivos."""

import pandas as pd
from scipy.stats import kruskal
import scikit_posthocs as sp

# Supondo que você tenha carregado seus dados no DataFrame `df`
# Certifique-se de que as colunas correspondem aos grupos mencionados
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']
data = df[columns]

# Separar os valores de cada grupo
t_student = data['T-Student']
full = data['Full']
bootstrap = data['Bootstrap']
split = data['Split']

# Aplicar o teste de Kruskal-Wallis
stat, p_value = kruskal(t_student, full, bootstrap, split)
print(f"Estatística do teste: {stat}")
print(f"P-valor: {p_value}")

if p_value < 0.05:
    print("Rejeitamos a hipótese nula: pelo menos um dos grupos é diferente.")
else:
    print("Não rejeitamos a hipótese nula: todos os grupos têm distribuições semelhantes.")

# Organizar os dados no formato longo para o teste de Dunn
data_long = pd.melt(data.reset_index(), id_vars=['index'], value_vars=columns)
data_long.columns = ['Index', 'Group', 'Value']

# Verificar se as colunas foram configuradas corretamente
assert 'Value' in data_long.columns, "A coluna 'Value' não está no DataFrame."
assert 'Group' in data_long.columns, "A coluna 'Group' não está no DataFrame."

# Aplicar o teste de Dunn com ajuste Bonferroni
posthoc = sp.posthoc_dunn(data_long, val_col='Value', group_col='Group', p_adjust='bonferroni')

print("\nResultados do teste de Dunn (pós-hoc):")
print(posthoc)

"""SHAPIRO-WILK TEST para verificar a normalidade Dados de Cobertura COM SW190"""

### upload arquivo
from google.colab import files
uploaded = files.upload()

df = pd.read_excel('coberturaSW_results.xlsx')
df

from scipy.stats import shapiro

# Selecionar as colunas desejadas como uma lista
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']

# Iterar sobre cada coluna e aplicar o teste Shapiro-Wilk
for column in columns:
    data = df[column]  # Selecionar os dados da coluna
    stat, p_value = shapiro(data)
    print(f"Coluna: {column}")
    print(f"Estatística do teste: {stat}")
    print(f"P-valor: {p_value}")
    if p_value > 0.05:
        print("Não rejeitamos a hipótese nula: os dados seguem uma distribuição normal.\n")
    else:
        print("Rejeitamos a hipótese nula: os dados não seguem uma distribuição normal.\n")

"""O Teste de Kruskal-Wallis: pra determina se há diferenças significativas entre os grupos. E o Teste de Dunn: Pra identificar quais grupos específicos apresentam diferenças significativas.  O ajuste de Bonferroni é usado para evitar falsos positivos."""

import pandas as pd
from scipy.stats import kruskal
import scikit_posthocs as sp

# Supondo que você tenha carregado seus dados no DataFrame `df`
# Certifique-se de que as colunas correspondem aos grupos mencionados
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']
data = df[columns]

# Separar os valores de cada grupo
t_student = data['T-Student']
full = data['Full']
bootstrap = data['Bootstrap']
split = data['Split']

# Aplicar o teste de Kruskal-Wallis
stat, p_value = kruskal(t_student, full, bootstrap, split)
print(f"Estatística do teste: {stat}")
print(f"P-valor: {p_value}")

if p_value < 0.05:
    print("Rejeitamos a hipótese nula: pelo menos um dos grupos é diferente.")
else:
    print("Não rejeitamos a hipótese nula: todos os grupos têm distribuições semelhantes.")

# Organizar os dados no formato longo para o teste de Dunn
data_long = pd.melt(data.reset_index(), id_vars=['index'], value_vars=columns)
data_long.columns = ['Index', 'Group', 'Value']

# Verificar se as colunas foram configuradas corretamente
assert 'Value' in data_long.columns, "A coluna 'Value' não está no DataFrame."
assert 'Group' in data_long.columns, "A coluna 'Group' não está no DataFrame."

# Aplicar o teste de Dunn com ajuste Bonferroni
posthoc = sp.posthoc_dunn(data_long, val_col='Value', group_col='Group', p_adjust='bonferroni')

print("\nResultados do teste de Dunn (pós-hoc):")
print(posthoc)

"""SHAPIRO-WILK TEST para verificar a normalidade Dados de Largura COM SW190"""

### upload arquivo
from google.colab import files
uploaded = files.upload()

df = pd.read_excel('larguraSW_results.xlsx')
df

"""O Teste de Kruskal-Wallis: pra determina se há diferenças significativas entre os grupos. E o Teste de Dunn: Pra identificar quais grupos específicos apresentam diferenças significativas.  O ajuste de Bonferroni é usado para evitar falsos positivos."""

import pandas as pd
from scipy.stats import kruskal
import scikit_posthocs as sp

# Supondo que você tenha carregado seus dados no DataFrame `df`
# Certifique-se de que as colunas correspondem aos grupos mencionados
columns = ['T-Student', 'Full', 'Bootstrap', 'Split']
data = df[columns]

# Separar os valores de cada grupo
t_student = data['T-Student']
full = data['Full']
bootstrap = data['Bootstrap']
split = data['Split']

# Aplicar o teste de Kruskal-Wallis
stat, p_value = kruskal(t_student, full, bootstrap, split)
print(f"Estatística do teste: {stat}")
print(f"P-valor: {p_value}")

if p_value < 0.05:
    print("Rejeitamos a hipótese nula: pelo menos um dos grupos é diferente.")
else:
    print("Não rejeitamos a hipótese nula: todos os grupos têm distribuições semelhantes.")

# Organizar os dados no formato longo para o teste de Dunn
data_long = pd.melt(data.reset_index(), id_vars=['index'], value_vars=columns)
data_long.columns = ['Index', 'Group', 'Value']

# Verificar se as colunas foram configuradas corretamente
assert 'Value' in data_long.columns, "A coluna 'Value' não está no DataFrame."
assert 'Group' in data_long.columns, "A coluna 'Group' não está no DataFrame."

# Aplicar o teste de Dunn com ajuste Bonferroni
posthoc = sp.posthoc_dunn(data_long, val_col='Value', group_col='Group', p_adjust='bonferroni')

print("\nResultados do teste de Dunn (pós-hoc):")
print(posthoc)